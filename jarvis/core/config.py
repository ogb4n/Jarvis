from pydantic_settings import BaseSettings
from typing import Optional

class Settings(BaseSettings):
    mongodb_url: str
    database_name: str 
    api_host: str 
    api_port: int 
    audio_storage_path: str = "./audio_files"
    openai_api_key: Optional[str] = None
    
    # Audio device configuration
    audio_input_device: Optional[int] = None  # None = default device
    audio_output_device: Optional[int] = None  # None = default device
    audio_sample_rate: int = 16000
    audio_channels: int = 1

    class Config:
        env_file = ".env"

settings = Settings()

class OpenAPISettings():
    title: str = "Jarvis Voice Assistant API"
    version: str = "0.1.0"
    description: str = (
        """
    ## ğŸ›°ï¸ Jarvis Satellite-Based Voice Assistant API
    
    A distributed voice assistant system with centralized intelligence and satellite-based audio processing.
    
    ### ğŸ—ï¸ Architecture
    **Server-Satellite Distributed System:**
    - ğŸ–¥ï¸ **Central Server** (this API): Command processing, AI logic, database
    - ğŸ›°ï¸ **Satellites**: Audio capture, speech-to-text, text-to-speech
    - ï¿½ **Communication**: REST API / WebSocket
    
    ### ğŸ”§ Core Features
    - ğŸ’¬ **Command Processing**: Natural language understanding
    - ï¿½ï¸ **Session Management**: Multi-satellite conversation tracking  
    - ğŸ“Š **Satellite Monitoring**: Real-time status and health
    - ğŸ” **Command History**: Full audit trail and analytics
    - ğŸ¯ **Extensible Logic**: Easy to add new commands and integrations
    
    ### ğŸš€ Getting Started
    1. **Check system health**: `GET /health`
    2. **View active satellites**: `GET /api/audio/satellites`
    3. **Process a command**: `POST /api/audio/process-command`
    4. **Start conversation mode**: `POST /api/conversation/start`
    
    ### ğŸ›°ï¸ Satellite Integration
    **Your satellites should:**
    1. Capture audio locally
    2. Convert speech-to-text (using Whisper, etc.)
    3. Send text commands to `/api/audio/process-command`
    4. Receive response and convert to speech
    5. Play audio response to user
    
    ### ğŸ“– Example Satellite Flow
    ```
    User: "Hey Jarvis, quelle heure est-il ?"
    Satellite: [Audio capture] â†’ [STT] â†’ "quelle heure est-il"
    API: Process command â†’ {"type": "time", "text": "Il est 14:30"}
    Satellite: [TTS] â†’ [Audio playback] â†’ "Il est 14:30"
    ```
    """
    )
    contact_name: str = "Jarvis Assistant"
    contact_url: str = "https://github.com/ogb4n/Jarvis"
    license_name: str = "MIT License"
    license_url: str = "https://opensource.org/licenses/MIT"
    openapi_tags: list = [
        {
            "name": "system",
            "description": "ğŸ”§ System health, status, and core information endpoints",
        },
        {
            "name": "satellite-audio", 
            "description": "ğŸ›°ï¸ Satellite-based audio processing and command handling",
        },
        {
            "name": "conversation",
            "description": "ğŸ’¬ Conversation management and session tracking (satellite coordination)",
        },
    ]